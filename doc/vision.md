# 1. Технологии

Для реализации MVP Telegram-бота выбран следующий стек:

* **Язык программирования:** Python 3.11+
* **Telegram API:** `python-telegram-bot`
* **LLM-провайдер:** OpenRouter через OpenAI client (используется для генерации конспектов и перевода текста на русский язык)
* **Парсинг PDF:** `pdfplumber` или `PyPDF2` для извлечения текста из PDF
* **Парсинг текста:** встроенные возможности Python (строки, регулярные выражения)
* **Хранение данных:** только в памяти (`dict`/`list`), без баз данных
* **Тестирование:** `pytest`
* **Окружение:** `uv`
* **Автоматизация:** `Makefile`
* **Деплой:** `Docker`
---

# 2. Принципы разработки

- **KISS (Keep It Simple, Stupid):** минимальная сложность решений, использование только необходимых инструментов.  
- **MVP-first:** сначала реализуем минимально жизнеспособный продукт (работа с текстом и PDF, генерация 2 видов конспекта)  
- **Итеративная разработка:** маленькие шаги → быстрые проверки → улучшения
- **Прозрачность:** простая и понятная архитектура, без скрытых зависимостей
- **Легко поддерживать:** читаемый код, простая модульная структура 
- **Минимум инфраструктуры:** без баз данных и сторонних сервисов, всё хранится в памяти
---

# 3. Структура проекта 
```
llmstart-homework/
├── bot/                # Логика Telegram-бота
│   ├── main.py         # Основной вход: обработка сообщений
│   └── link_parser.py  # Парсер для извлечения текста из HTML и PDF по ссылкам
├── llm/                # Работа с LLM (openrouter)
│   └── client.py
├── tests/              # Тесты (pytest)
│   ├── test_basic.py
│   └── test_link_parser.py  # Тесты для парсера ссылок
├── requirements.uv     # Зависимости для uv
├── Makefile            # Автоматизация
├── Dockerfile          # Деплой
├── README.md
└── doc/
    ├── product_idea.md
    └── vision.md
```
---

# 4. Архитектура проекта

1. Пользователь отправляет в Telegram:
   - PDF файл (например, статья с arxiv.org/pdf)
   - или текстовое сообщение.

2. `bot/main.py`:
   - Определяет тип входа (текст или PDF).
   - Если PDF → передаёт в `parser.py` для извлечения текста.

3. `bot/parser.py`:
   - Извлекает чистый текст из PDF (без рекламы и артефактов).
   - Проверяет размер текста.
   - Если текст превышает лимит LLM:
     - Делит на **чанки** (например, по 3000–4000 символов).
     - Возвращает список частей.

4. `llm/client.py`:
   - Для каждого чанка делает локальное summary в выбранном формате (конспект по разделам или объяснение для новичка).
   - После обработки всех частей собирает результаты.
   - Генерирует итоговое объединённое summary (агрегация).

5. Результат отправляется пользователю в Telegram:
   - Всегда **на русском языке**.
   - В формате, который выбрал пользователь.


### Ключевые особенности архитектуры

- **Chunking для больших документов**: PDF делится на части, чтобы весь текст учитывался.
- **Многошаговая работа с LLM**: сначала частичные конспекты, затем итоговое объединение.
- **Простая логика хранения**: история сообщений хранится в памяти (dict/list).
- **Чистая изоляция слоёв**:
  - `bot/` — интерфейс Telegram
  - `parser.py` — извлечение текста
  - `llm/` — работа с моделью
- **Обработка ошибок**: если текст не удалось извлечь, бот сообщает пользователю

---

# 5. Работа с LLM

### Основные принципы
- Используется **OpenRouter через OpenAI client**.  
- LLM выполняет две задачи:
  1. Генерация конспекта в выбранном формате (`sections` или `beginner`).  
  2. Автоматический перевод текста на русский язык (если текст на английском).  
- **Chunking**: для больших PDF текст делится на части (чанки), чтобы каждая часть помещалась в лимит LLM.  
- Итоговый конспект формируется как **объединение результатов всех чанков**.  
---

# 6. Мониторинг LLM
### Цели мониторинга
- Отслеживать успешность генерации конспектов.  
- Фиксировать ошибки при работе с LLM.  
- Следить за временем обработки сообщений (важно для больших PDF).  

### Реализация в MVP
- Все логи хранятся **локально в памяти** и выводятся в консоль.  
- Для каждого запроса фиксируем:
  - Тип входа (`text` или `pdf`).  
  - Размер текста / количество чанков.  
  - Выбранный формат конспекта (`sections` или `beginner`).  
  - Статус обработки (`success` / `error`).  
  - Время обработки.  

Пример записи:

```python
log_entry = {
    "input_type": "pdf",
    "chunks": 3,
    "summary_type": "sections",
    "status": "success",
    "time_sec": 12.4
}
print(log_entry)
```
---

# 7. Сценарии работы

### Поток взаимодействия пользователя с ботом

1. **Запуск бота**  
   Пользователь открывает Telegram и запускает бота.

2. **Выбор формата конспекта**  
   Бот предлагает выбрать один из двух вариантов:
   - Конспект по разделам (`sections`)  
   - Объяснение для новичка (`beginner`)

3. **Отправка текста или PDF**  
   Пользователь отправляет:
   - Текстовое сообщение  
   - PDF-файл (например, статья с arxiv.org/pdf)

4. **Парсинг и обработка текста**  
   - Если PDF → бот извлекает текст и делит его на чанки при необходимости.  
   - Для каждого чанка LLM создаёт частичный конспект на русском языке.

5. **Объединение результатов**  
   - Все частичные конспекты объединяются в итоговый конспект.  

6. **Отправка результата**  
   - Итоговый конспект отправляется пользователю в выбранном формате.  
   - Конспект всегда на русском языке.


### Ключевые моменты
- Каждый запрос обрабатывается **отдельно**, история не сохраняется.  
- Пользователь всегда сначала выбирает формат, затем отправляет текст или PDF.  
- Для больших PDF весь текст учитывается через chunking и агрегирование конспектов.  
---
# 8. Деплой

### Основные принципы
- Деплой минимально жизнеспособного продукта через **Docker**.  
- Поддержка локального запуска и развертывания на сервере.  
- Простой и воспроизводимый образ для проверки идеи.  



### Структура Docker

1. **Dockerfile**  
   - Устанавливает Python 3.11+.  
   - Копирует исходный код бота.  
   - Устанавливает зависимости из `requirements.uv`.  
   - Настраивает запуск бота через uvicorn.  

2. **Makefile**  
   - Упрощает сборку и запуск Docker-контейнера:  
     ```bash
     make build   # сборка образа
     make run     # запуск контейнера
     make test    # запуск тестов
     ```  



### Особенности KISS
- Нет сложных скриптов деплоя.  
- Образ содержит только необходимое для запуска бота.  
- Настройки через переменные окружения (API ключ LLM, токен Telegram).  
---
# 9. Подход к конфигурированию

### Принципы
- Конфигурация через **переменные окружения** или `.env` файл.  
- Нет сложных конфигов — только необходимые параметры для работы MVP.  

### Основные настройки
- `TELEGRAM_BOT_TOKEN` — токен бота Telegram.  
- `OPENROUTER_API_KEY` — ключ для LLM через OpenRouter.  
- `MAX_CHUNK_SIZE` — максимальный размер чанка для LLM (например, 3000–4000 символов).  
- `LOG_LEVEL` — уровень логирования (INFO, ERROR и т.д.).  

### Особенности KISS
- Минимальный набор параметров.  
- Все настройки легко менять без изменения кода.  

---

# 10. Подход к логированию

### Принципы
- Логи нужны для отладки работы бота и мониторинга LLM.  
- Простой подход: **консоль + опциональный файл логов**.  

### Что логируем
- Тип входа (`text` / `pdf`).  
- Размер текста / количество чанков.  
- Выбранный формат конспекта (`sections` / `beginner`).  
- Ошибки при парсинге PDF или вызове LLM.  
- Время обработки запроса.  

### Реализация MVP
- Простейший лог через `print()` или модуль `logging`.  
- Нет внешних сервисов мониторинга.  
- Ошибки и информация для разработчика доступны сразу.  

### Особенности KISS
- Только самое необходимое логирование для проверки идеи.  
- Логи не сохраняются в базу данных, всё локально.  
